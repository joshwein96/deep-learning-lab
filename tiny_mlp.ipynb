{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d654b236",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import wandb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from fastprogress import master_bar, progress_bar\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9cce78ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33m04janik\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5dfc3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a04ea48",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = list(df.columns)\n",
    "\n",
    "f_target, f_home_team_name, f_away_team_name, f_match_date = [[feature] for feature in columns[1:5]]\n",
    "f_league_name, f_league_id, f_is_cup, f_home_team_coach_id, f_away_team_coach_id = [[feature] for feature in columns[5:10]]\n",
    "\n",
    "f_home_team_history_match_date = columns[10:20]\n",
    "f_home_team_history_is_play_home = columns[20:30]\n",
    "f_home_team_history_is_cup = columns[30:40]\n",
    "f_home_team_history_goal = columns[40:50]\n",
    "f_home_team_history_opponent_goal = columns[50:60]\n",
    "f_home_team_history_rating = columns[60:70]\n",
    "f_home_team_history_opponent_rating = columns[70:80]\n",
    "f_home_team_history_coach = columns[80:90]\n",
    "f_home_team_history_league_id = columns[90:100]\n",
    "f_away_team_history_match_date = columns[100:110]\n",
    "f_away_team_history_is_play_home = columns[110:120]\n",
    "f_away_team_history_is_cup = columns[120:130]\n",
    "f_away_team_history_goal = columns[130:140]\n",
    "f_away_team_history_opponent_goal = columns[140:150]\n",
    "f_away_team_history_rating = columns[150:160]\n",
    "f_away_team_history_opponent_rating = columns[160:170]\n",
    "f_away_team_history_coach = columns[170:180]\n",
    "f_away_team_history_league_id = columns[180:190]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9297723f",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_shitty = f_match_date + f_home_team_coach_id + f_away_team_coach_id + f_home_team_history_match_date + f_home_team_history_coach + f_away_team_history_match_date + f_away_team_history_coach\n",
    "features_boolean = f_is_cup + f_home_team_history_is_play_home + f_home_team_history_is_cup + f_away_team_history_is_play_home + f_away_team_history_is_cup\n",
    "features_numerical = f_home_team_history_goal + f_home_team_history_opponent_goal + f_home_team_history_rating + f_home_team_history_opponent_rating + f_away_team_history_goal + f_away_team_history_opponent_goal + f_away_team_history_rating + f_away_team_history_opponent_rating\n",
    "features_categorical = f_home_team_name + f_away_team_name + f_league_name + f_league_id + f_home_team_history_league_id + f_away_team_history_league_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6caa17dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop NaN and duplicates\n",
    "df = df.dropna()\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "# data processing \n",
    "data_set = df[['id']]\n",
    "data_set = data_set.join(pd.get_dummies(df['target']))\n",
    "data_set = data_set.join(df[features_boolean].astype(int))\n",
    "data_set = data_set.join(df[features_numerical].astype(float))\n",
    "data_set = data_set.join(pd.get_dummies(df[features_categorical[0:3]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c496231",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64117, 11037)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_set.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e896b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = data_set.columns[1:4]\n",
    "features = data_set.columns[4:]\n",
    "\n",
    "# transform dataframe to tensor\n",
    "x = torch.tensor(data_set[features].values).float()\n",
    "y = torch.tensor(data_set[targets].values).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ebe806e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataSet():\n",
    "    \n",
    "    def __init__(self,x,y):\n",
    "        self.x_train = x\n",
    "        self.y_train = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y_train)\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        return self.x_train[idx], self.y_train[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d56d94e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data in train and test set\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b65e849c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(DataSet(x_train,y_train), batch_size=128, shuffle=True)\n",
    "test_loader =  torch.utils.data.DataLoader(DataSet(x_test,y_test), batch_size=128, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "69125b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(11033, 5000)\n",
    "        self.fc2 = nn.Linear(5000, 1000)\n",
    "        self.fc3 = nn.Linear(1000, 3)\n",
    "        nn.init.kaiming_uniform_(self.fc1.weight, nonlinearity='relu')\n",
    "        nn.init.kaiming_uniform_(self.fc2.weight, nonlinearity='relu')\n",
    "        nn.init.xavier_uniform_(self.fc3.weight)\n",
    "        nn.init.constant_(self.fc1.bias, 0.0)\n",
    "        nn.init.constant_(self.fc2.bias, 0.0)\n",
    "        nn.init.constant_(self.fc3.bias, 0.0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.leaky_relu(self.fc1(x))\n",
    "        x = F.leaky_relu(self.fc2(x))\n",
    "        x = F.softmax(self.fc3(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "54024221",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLP()\n",
    "model.float()\n",
    "\n",
    "learning_rate = 0.003\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "adec22e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model):\n",
    "    \n",
    "    train_mode = model.training\n",
    "    \n",
    "    if train_mode:\n",
    "        model.eval()\n",
    "    \n",
    "    confusion = np.zeros((3,3), dtype=np.int32)\n",
    "    \n",
    "    for inputs, labels in DataSet(x_test, y_test):\n",
    "        outputs = model(inputs).detach().numpy()\n",
    "        confusion[np.argmax(labels), np.argmax(outputs)] += 1\n",
    "\n",
    "    total = np.sum(confusion)\n",
    "    accuracy = np.sum(np.diag(confusion)) / total\n",
    "    per_class_accuracy = np.diag(confusion) / np.sum(confusion, axis=1)\n",
    "    \n",
    "    if train_mode:\n",
    "        model.train()\n",
    "\n",
    "    return accuracy, per_class_accuracy, confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5e31bab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, epochs):\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    # construct name\n",
    "    model_name = model.__class__.__name__\n",
    "    optimizer_name = optimizer.__class__.__name__\n",
    "    run_name = f'{model_name}-{optimizer_name}-lr{learning_rate}'\n",
    "    \n",
    "    # init weight and biases\n",
    "    with wandb.init(project='DLL-Project', name=run_name) as run:\n",
    "        \n",
    "        # log some info\n",
    "        run.config.learning_rate = learning_rate\n",
    "        run.config.optimizer = optimizer.__class__.__name__\n",
    "        run.watch(model)\n",
    "        \n",
    "        # progress bar\n",
    "        mb = master_bar(range(epochs))\n",
    "        \n",
    "        for epoch in mb:\n",
    "            \n",
    "            for inputs, labels in progress_bar(iter(train_loader), parent=mb):\n",
    "\n",
    "                # set all parameter gradients to zero\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # compute the forward pass\n",
    "                outputs = model.forward(inputs)\n",
    "\n",
    "                # compute loss and backpropagate gradients\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "\n",
    "                # update parameters\n",
    "                optimizer.step()\n",
    "\n",
    "                # log the loss\n",
    "                run.log({'loss': loss})\n",
    "                \n",
    "            # evaluate the model\n",
    "            accuracy, per_class_accuracy, confusion = test_model(model)\n",
    "            mb.main_bar.comment = f'val acc:{accuracy}'\n",
    "\n",
    "            # log the data\n",
    "            run.log({'accuracy': accuracy, 'epoch': epoch})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "46f58cb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.17"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/janik/Desktop/wandb/run-20220526_141955-3518k6yz</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/04janik/DLL-Project/runs/3518k6yz\" target=\"_blank\">MLP-SGD-lr0.003</a></strong> to <a href=\"https://wandb.ai/04janik/DLL-Project\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/n4/r1237jsd757by57pvf6gql6h0000gn/T/ipykernel_41145/1524567729.py:18: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = F.softmax(self.fc3(x))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94c6205403904489b31ec06b02c8a33c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.000 MB of 0.000 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>epoch</td><td>▁</td></tr><tr><td>loss</td><td>█▆▅▅▃▄▅▂▅▅▇▅▄▁▄▃▃▅▅▄▄▂▃█▅▆▄▅▃▂▅▅▄▂▄▄▃▇▄▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.4777</td></tr><tr><td>epoch</td><td>0</td></tr><tr><td>loss</td><td>1.07441</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">MLP-SGD-lr0.003</strong>: <a href=\"https://wandb.ai/04janik/DLL-Project/runs/3518k6yz\" target=\"_blank\">https://wandb.ai/04janik/DLL-Project/runs/3518k6yz</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220526_141955-3518k6yz/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_model(model, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3adbd56",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/n4/r1237jsd757by57pvf6gql6h0000gn/T/ipykernel_41145/1524567729.py:18: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = F.softmax(self.fc3(x))\n"
     ]
    }
   ],
   "source": [
    "test_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e73fb5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
